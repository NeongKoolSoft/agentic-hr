import os
import re
import streamlit as st

from langchain_community.utilities import SQLDatabase
from langchain_community.tools import QuerySQLDatabaseTool
from langchain_google_genai import ChatGoogleGenerativeAI

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


# -----------------------------
# 0) SQL ì •ì œ/ê²€ì¦ ìœ í‹¸
# -----------------------------
def strip_code_fence(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"^```(?:sql)?\s*", "", s, flags=re.IGNORECASE)
    s = re.sub(r"\s*```$", "", s)
    return s.strip()


def normalize_sql(s: str) -> str:
    s = strip_code_fence(s)
    s = re.sub(r"^\s*(sql|sqlite)\s*:?\s*", "", s, flags=re.IGNORECASE).strip()

    # SELECT/WITH ì‹œì‘ ì „ ëª¨ë“  ë¬¸ì ì œê±° (ite ê°™ì€ ì°Œêº¼ê¸° ì œê±°)
    m = re.search(r"\b(select|with)\b", s, flags=re.IGNORECASE)
    if m:
        s = s[m.start():].strip()

    s = re.sub(r"\s*```$", "", s).strip()
    return s


def is_safe_readonly_sql(sql: str) -> bool:
    if not sql:
        return False

    lowered = sql.strip().lower()
    parts = [p.strip() for p in lowered.split(";") if p.strip()]
    if len(parts) != 1:
        return False

    forbidden = [
        "insert", "update", "delete", "drop", "alter", "create", "replace",
        "truncate", "attach", "detach", "pragma", "vacuum"
    ]
    if any(tok in lowered for tok in forbidden):
        return False

    return lowered.startswith("select") or lowered.startswith("with")


# -----------------------------
# 1) í˜ì´ì§€ ì„¤ì • / ì‚¬ì´ë“œë°”
# -----------------------------
st.set_page_config(page_title="ë„ì¿¨ AI ë°ì´í„° ë¹„ì„œ", layout="wide")
st.sidebar.title("âš™ï¸ ì„¤ì •")

api_key = st.sidebar.text_input("Gemini API Key", type="password", value="")
db_uri = st.sidebar.text_input("DB URI", value="sqlite:///erp_sample.db")
st.sidebar.caption("â€» DB URI ì˜ˆì‹œ: sqlite:///erp_sample.db")

if not api_key:
    st.warning("ì‚¬ì´ë“œë°”ì— Gemini API í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

os.environ["GOOGLE_API_KEY"] = api_key


# -----------------------------
# 2) DB / LLM ì—°ê²°
# -----------------------------
db = SQLDatabase.from_uri(db_uri)
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
execute_query = QuerySQLDatabaseTool(db=db)
schema_text = db.get_table_info()


# -----------------------------
# 3) SQL ìƒì„± / ë‹µë³€ í”„ë¡¬í”„íŠ¸
# -----------------------------
sql_prompt = PromptTemplate.from_template(
    """You are a {dialect} SQL expert.
Write ONE SQLite query that answers the question using the schema.

Rules:
- Return ONLY SQL (no explanation).
- Do NOT use markdown code fences.
- Read-only SELECT/CTE only. Never use INSERT/UPDATE/DELETE/DROP/ALTER/CREATE.
- Prefer "ORDER BY ... DESC LIMIT 1" for "top/highest" questions.
- Use only tables/columns that exist in the schema.

Schema:
{schema}

Question:
{question}

SQL:
"""
)

write_query = (
    {
        "dialect": lambda _: db.dialect,
        "schema": lambda _: schema_text,
        "question": RunnablePassthrough(),
    }
    | sql_prompt
    | llm
    | StrOutputParser()
)

answer_prompt = PromptTemplate.from_template(
    """ì£¼ì–´ì§„ ì§ˆë¬¸, SQL ì¿¼ë¦¬, ê·¸ë¦¬ê³  SQL ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µí•˜ì„¸ìš”.
ì§ˆë¬¸: {question}
SQL ì¿¼ë¦¬: {query}
SQL ê²°ê³¼: {result}
ë‹µë³€:"""
)


# -----------------------------
# 4) ì§ˆë¬¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------
def run_question(user_question: str) -> str:
    raw_sql = write_query.invoke(user_question)
    generated_sql = normalize_sql(raw_sql)

    if not is_safe_readonly_sql(generated_sql):
        st.error("ì•ˆì „ìƒ ì´ìœ ë¡œ ì‹¤í–‰í•  ìˆ˜ ì—†ëŠ” SQLì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.")
        with st.expander("ğŸ” ìƒì„±ëœ SQL(ì‹¤í–‰ ì°¨ë‹¨)"):
            st.code(generated_sql, language="sql")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì•ˆì „ì„ ìœ„í•´ í•´ë‹¹ ìš”ì²­ì€ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    try:
        result = execute_query.invoke({"query": generated_sql})
    except Exception as e:
        result = f"Error: {e}"

    response_text = (
        {"question": lambda _: user_question,
         "query": lambda _: generated_sql,
         "result": lambda _: result}
        | answer_prompt
        | llm
        | StrOutputParser()
    ).invoke({})

    st.markdown(response_text)
    with st.expander("ğŸ” ì‹¤í–‰ëœ SQL ì¿¼ë¦¬ í™•ì¸"):
        st.code(generated_sql, language="sql")

    return response_text


# -----------------------------
# 5) ë©”ì¸ UI
# -----------------------------
st.title("ğŸŒ¿ ë„ì¿¨ AI ë°ì´í„° ì—ì´ì „íŠ¸")
st.subheader("ERP ë°ì´í„°ë¥¼ ìì—°ì–´ë¡œ ì¡°íšŒí•˜ì„¸ìš”")

# ì„¸ì…˜ ìƒíƒœ
if "messages" not in st.session_state:
    st.session_state.messages = []
if "pending_prompt" not in st.session_state:
    st.session_state.pending_prompt = None

# âœ… ëŒ€í‘œ ì§ˆë¬¸ 10ê°œ (ì¹©)
st.markdown("#### ğŸ’¡ ëŒ€í‘œ ì§ˆë¬¸ 10ê°œ")
chip_questions = [
    "í˜„ì¬ ë“±ë¡ëœ ìƒí’ˆë“¤ ì¤‘ ë§¤ì¶œì•¡ì´ ê°€ì¥ í° ê²ƒì€ ë¬´ì—‡ì´ê³  ê¸ˆì•¡ì€ ì–¼ë§ˆì•¼?",
    "ì´ë²ˆ ë‹¬(ë˜ëŠ” ìµœê·¼ ê¸°ê°„) ë§¤ì¶œ í•©ê³„ëŠ” ì–¼ë§ˆì•¼?",
    "ìƒí’ˆë³„ ë§¤ì¶œ TOP 5ë¥¼ ë³´ì—¬ì¤˜.",
    "ë§¤ì¶œì´ 0ì›ì´ê±°ë‚˜ ê±°ì˜ ì—†ëŠ” ìƒí’ˆì´ ìˆì–´?",
    "ìµœê·¼ 7ì¼ ë™ì•ˆ ê°€ì¥ ë§ì´ íŒ”ë¦° ìƒí’ˆì€ ë­ì•¼?",
    "íŠ¹ì • ìƒí’ˆ(ì˜ˆ: ë„ì¿¨OS Pro)ì˜ ë§¤ì¶œ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜.",
    "ì˜¤ëŠ˜ ê¸°ì¤€ ë¯¸ìˆ˜ê¸ˆ(ë˜ëŠ” ì™¸ìƒ)ì´ ìˆëŠ” ê±°ë˜ì²˜ê°€ ìˆì–´?",
    "ê±°ë˜ì²˜ë³„ ë§¤ì¶œ TOP 5ë¥¼ ì•Œë ¤ì¤˜.",
    "ì¬ê³ ê°€ ë¶€ì¡±í•œ(ì˜ˆ: 10ê°œ ì´í•˜) ìƒí’ˆ ëª©ë¡ì„ ë³´ì—¬ì¤˜.",
    "ì§€ë‚œë‹¬ ëŒ€ë¹„ ì´ë²ˆ ë‹¬ ë§¤ì¶œì´ ì–¼ë§ˆë‚˜ ì¦ê°€/ê°ì†Œí–ˆì–´?",
]

# ì¹©ì„ í•œ ì¤„ì— ë„ˆë¬´ ë§ì´ ë¶™ì´ë©´ ê¹¨ì ¸ì„œ 5ê°œì”© ë‚˜ëˆ”
rows = [chip_questions[i:i+5] for i in range(0, len(chip_questions), 5)]
for row in rows:
    cols = st.columns(len(row))
    for i, q in enumerate(row):
        if cols[i].button(q, use_container_width=True):
            st.session_state.pending_prompt = q
            st.rerun()

st.divider()

# ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# âœ… ì¹© í´ë¦­ìœ¼ë¡œ ë“¤ì–´ì˜¨ ì§ˆë¬¸ ì²˜ë¦¬
if st.session_state.pending_prompt:
    prompt = st.session_state.pending_prompt
    st.session_state.pending_prompt = None

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("DB ë¶„ì„ ì¤‘..."):
            response = run_question(prompt)

    st.session_state.messages.append({"role": "assistant", "content": response})

# ì‚¬ìš©ì ì§ì ‘ ì…ë ¥
user_input = st.chat_input("ì˜ˆ: ê°€ì¥ ë§¤ì¶œì´ ë†’ì€ ìƒí’ˆì€ ë­ì•¼?")
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("DB ë¶„ì„ ì¤‘..."):
            response = run_question(user_input)

    st.session_state.messages.append({"role": "assistant", "content": response})
